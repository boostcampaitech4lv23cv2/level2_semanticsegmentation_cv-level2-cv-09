{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data_dir = '../data/'\n",
    "\n",
    "# mode='train'\n",
    "# src_data_json_path = src_data_dir + '/train.json'\n",
    "# dst_data_dir = '../data/mmseg/'\n",
    "\n",
    "# mode='val'\n",
    "# src_data_json_path = src_data_dir + '/val.json'\n",
    "# dst_data_dir = '../data/mmseg/'\n",
    "\n",
    "mode='test'\n",
    "src_data_json_path = src_data_dir + '/test.json'\n",
    "dst_data_dir = '../data/mmseg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Background', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic','Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, data_json_path, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.coco = COCO(data_json_path)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(self.data_dir, image_infos['file_name']))\n",
    "        # images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images = images.astype(np.float32)\n",
    "        # images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # General trash = 1, ... , Cigarette = 10\n",
    "            anns = sorted(anns, key=lambda idx : len(idx['segmentation'][0]), reverse=False)\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = classes.index(className)\n",
    "                masks[self.coco.annToMask(anns[i]) == 1] = pixel_value\n",
    "            masks = masks.astype(np.int8)\n",
    "                        \n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            return images, image_infos\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[ 77.,  86.,  89.],\n",
       "         [ 70.,  79.,  82.],\n",
       "         [ 63.,  72.,  75.],\n",
       "         ...,\n",
       "         [ 18.,  20.,  28.],\n",
       "         [ 18.,  20.,  28.],\n",
       "         [ 18.,  20.,  28.]],\n",
       " \n",
       "        [[ 68.,  77.,  80.],\n",
       "         [ 66.,  75.,  78.],\n",
       "         [ 61.,  70.,  73.],\n",
       "         ...,\n",
       "         [ 18.,  20.,  28.],\n",
       "         [ 17.,  19.,  27.],\n",
       "         [ 17.,  19.,  27.]],\n",
       " \n",
       "        [[ 46.,  55.,  58.],\n",
       "         [ 47.,  56.,  59.],\n",
       "         [ 45.,  54.,  57.],\n",
       "         ...,\n",
       "         [ 17.,  19.,  27.],\n",
       "         [ 17.,  19.,  27.],\n",
       "         [ 16.,  18.,  26.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 46.,  58.,  76.],\n",
       "         [ 33.,  45.,  63.],\n",
       "         [ 31.,  43.,  61.],\n",
       "         ...,\n",
       "         [ 82., 100., 111.],\n",
       "         [ 43.,  55.,  67.],\n",
       "         [ 44.,  54.,  64.]],\n",
       " \n",
       "        [[ 31.,  45.,  63.],\n",
       "         [ 23.,  37.,  55.],\n",
       "         [ 25.,  39.,  57.],\n",
       "         ...,\n",
       "         [ 72.,  94., 105.],\n",
       "         [ 38.,  54.,  66.],\n",
       "         [ 44.,  56.,  68.]],\n",
       " \n",
       "        [[ 31.,  45.,  63.],\n",
       "         [ 23.,  37.,  55.],\n",
       "         [ 27.,  41.,  59.],\n",
       "         ...,\n",
       "         [ 78., 102., 114.],\n",
       "         [ 47.,  63.,  75.],\n",
       "         [ 42.,  56.,  68.]]], dtype=float32),\n",
       " {'license': 0,\n",
       "  'url': None,\n",
       "  'file_name': 'batch_01_vt/0021.jpg',\n",
       "  'height': 512,\n",
       "  'width': 512,\n",
       "  'date_captured': None,\n",
       "  'id': 0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomDataLoader(data_dir=src_data_dir, data_json_path=src_data_json_path, mode=mode, transform=None)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A directory - ../data/mmseg/test is created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 819/819 [00:08<00:00, 93.59it/s]\n"
     ]
    }
   ],
   "source": [
    "if mode == 'train':\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'images/train')\n",
    "    annotations_save_dir = os.path.join(dst_data_dir, 'annotations/train')\n",
    "elif mode == 'val':\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'images/val')\n",
    "    annotations_save_dir = os.path.join(dst_data_dir, 'annotations/val')\n",
    "else:  # mode == 'test'\n",
    "    images_save_dir = os.path.join(dst_data_dir, 'test')\n",
    "    annotations_save_dir = None\n",
    "    \n",
    "if not os.path.exists(images_save_dir):\n",
    "    os.makedirs(images_save_dir)\n",
    "    print('A directory - ' + images_save_dir + ' is created.')\n",
    "          \n",
    "if annotations_save_dir and not os.path.exists(annotations_save_dir):\n",
    "    os.makedirs(annotations_save_dir)\n",
    "    print('A directory - ' + annotations_save_dir + ' is created.')\n",
    "    \n",
    "\n",
    "if mode in ('train', 'val'):\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, mask, image_infos = dataset[idx]\n",
    "        image_save_path = os.path.join(images_save_dir, f'{image_infos[\"id\"]:04}.jpg')\n",
    "        annotation_save_path = os.path.join(annotations_save_dir, f'{image_infos[\"id\"]:04}.png')\n",
    "        \n",
    "        cv2.imwrite(image_save_path, img)\n",
    "        cv2.imwrite(annotation_save_path, mask)\n",
    "\n",
    "elif mode == 'test':\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        img, image_infos = dataset[idx]\n",
    "        image_save_path = os.path.join(images_save_dir, f'{image_infos[\"id\"]:04}.jpg')\n",
    "        \n",
    "        cv2.imwrite(image_save_path, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8892ab59d46dba3f4efad217c937d392d78b127da621344609ec3a012e116b8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
