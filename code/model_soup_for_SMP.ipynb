{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 1.13.1+cu117\n",
      "GPU 사용 가능 여부: True\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "#!pip install albumentations==0.4.6\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from dataloader import CustomDataLoader\n",
    "from SMP_dataset import test\n",
    "\n",
    "dataset_path  = '../../data'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본코드\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from models import build\n",
    "build.register_encoder()\n",
    "from mmcv import Config\n",
    "# from mmseg.datasets import build_dataloader, build_dataset\n",
    "# from mmseg.models import build_segmentor\n",
    "# from mmseg.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint, load_state_dict\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "def uniform_soup(model, checkpoint_paths ,device = \"cpu\", by_name = False):\n",
    "    try:\n",
    "        import torch\n",
    "    except:\n",
    "        print(\"If you want to use 'Model Soup for Torch', please install 'torch'\")\n",
    "        return model\n",
    "    \n",
    "    dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)\n",
    "    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    model_dict = model.state_dict()\n",
    "    soups = {key:[] for key in model_dict}\n",
    "    checkpoint = {}\n",
    "    for i, checkpoint_path in enumerate(checkpoint_paths):\n",
    "        # checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        # state_dict = checkpoint.state_dict()\n",
    "        # model.load_state_dict(state_dict)\n",
    "        # weight_dict = checkpoint['state_dict']\n",
    "        weight_dict = checkpoint.state_dict()\n",
    "        for k, v in weight_dict.items():\n",
    "            soups[k].append(v)\n",
    "    if 0 < len(soups):\n",
    "        soups = {k:(torch.sum(torch.stack(v), axis = 0) / len(v)).type(v[0].dtype) for k, v in soups.items() if len(v) != 0}\n",
    "        model_dict.update(soups)\n",
    "        model.load_state_dict(model_dict)\n",
    "    \n",
    "    return model, checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. 모델 & checkpoint 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ model cfg path 적기 ################\n",
    "# cfg= Config.fromfile('/opt/ml/mmsegmentation/configs/_teajun_/segformer/segformer_mit-b5_8x1_1024x1024_160k_cityscapes.py')\n",
    "################ model cfg path 적기 ################\n",
    "model = smp.PAN(\n",
    "\t\t\tencoder_name=\"swin_encoder\",\n",
    "\t\t\tencoder_weights=\"imagenet\",\n",
    "            encoder_output_stride=32,\n",
    "\t\t\tin_channels=3,\n",
    "\t\t\tclasses=11\n",
    ")\n",
    "\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "checkpoint_paths = [\n",
    "    '/opt/ml/input/level2_semanticsegmentation_cv-level2-cv-09/code/saved/SMP_PAN_SwinL_StepLR_AUG2_best_model(pretrained).pt',\n",
    "    '/opt/ml/input/level2_semanticsegmentation_cv-level2-cv-09/code/saved/SMP_PAN_SwinL_StepLR_AUG2_CDBloss_best_model(pretrained).pt',\n",
    "    '/opt/ml/input/level2_semanticsegmentation_cv-level2-cv-09/code/saved/SMP_PAN_SwinL_StepLR_AUG2_DFloss_best_model(pretrained).pt',\n",
    "]\n",
    "################ soup할 checkpoint path 적기 ################\n",
    "device = \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. uniform soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Uniform Soup]\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "SAVED\n"
     ]
    }
   ],
   "source": [
    "################ save dir path 적기 ################\n",
    "save_dir_path = '/opt/ml/input/level2_semanticsegmentation_cv-level2-cv-09/code/saved/'\n",
    "name = 'AUG2LossSoup' # soup 이름 적기\n",
    "################ save dir path 적기 ################\n",
    "\n",
    "print(\"\\n[Uniform Soup]\")\n",
    "uniform_model, checkpoint = uniform_soup(model, checkpoint_paths, device = device)\n",
    "uniform_dict = checkpoint\n",
    "# uniform_dict['state_dict'] = uniform_model.state_dict()\n",
    "\n",
    "\n",
    "# torch.save(uniform_dict, save_dir_path+f'uniform_model_soup_{name}.pth')\n",
    "file_name = f'uniform_model_soup_{name}.pt'\n",
    "output_path = os.path.join(save_dir_path, file_name)\n",
    "torch.save(uniform_model, output_path)\n",
    "print(\"SAVED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
